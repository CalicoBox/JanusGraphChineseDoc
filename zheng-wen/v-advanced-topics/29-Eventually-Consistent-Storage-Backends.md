# 29. 最终一致性存储后端

在针对最后一致性的存储后端运行 JanusGraph 时，必须用特殊 JanusGraph 的配置去保证数据的一致性，必须对数据退化做特殊考虑。

该页总结了当 JanusGraph 运行在一个像 Apache Cassandra 或 Apache HBase 这样的最终一致性存储后端时一些需要考虑的方面。

## 29.1. 数据一致性
在最终一致的存储后端上，由于底层的数据存储并不提供事务隔离，JanusGraph 必须取锁来确保数据的一致性。因为效率原因，JanusGraph 默认不使用锁。因此，用户需要对每个模式元素定义一个一致性约束来控制是否使用锁。如下例所示，使用 `JanusGraphManagement.setConsistency(element, ConsistencyModifier.LOCK)` 以显式对一个模式元素启用锁。
```java
mgmt = graph.openManagement()
name = mgmt.makePropertyKey('consistentName').dataType(String.class).make()
index = mgmt.buildIndex('byConsistentName', Vertex.class).addKey(name).unique().buildCompositeIndex()
mgmt.setConsistency(name, ConsistencyModifier.LOCK) // Ensures only one name per vertex
mgmt.setConsistency(index, ConsistencyModifier.LOCK) // Ensures name uniqueness in the graph
mgmt.commit()
```
当更新一个受唯一性约束保护的元素时，JanusGraph 在调用 `tx.commit()` 时，会在事务结束时使用如下协议：

  1. 对所有具有一致性约束元素请求锁。
  2. 从存储后端中重新读取这些元素，并在进行修改之前验证它们与当前事务中的元素的状态相匹配。
  3. 针对存储后端保存事务的状态。
  4. 释放所有的锁。

上面在不考虑优化(比如本地冲突探测)和失败情况下的探测(比如过期锁)的基础上，对锁的控制进行简短的描述。

实际上锁应用机制是抽象的，因此 JanusGraph 可以使用多种方式来实现提供锁方法。实际上，JanusGraph 发行版中支持两种提供锁方法。
  1. 基于密钥一致性读写操作的锁的实现。只要存储后端支持密钥一致性操作即可(包括 Cassandra 和 HBase)，与底层存储后端无关。这是锁的默认实现机制，并且使用基于锁应用的时间戳来决定事务对锁的持有权。
  2. 基于 Astyanax 锁机制的 Cassandra 专属的锁的实现。

两种提供锁的方法都要求始终在集群的所有计算机上是同步的。

> **警告**
> 锁的实现并非在所有失败场景下都是健壮的。举个栗子，当一个 Cassandra 集群当机，运行数量低于法定人数时，便无法保证一致性。因此，在存储后端上，建议谨慎使用基于锁的一致性约束。对于那些需要严谨和/或频繁执行一致性约束的用例，推荐使用提供事务隔离机制的存储后端。

### 29.1.1. 无锁数据一致性
由于在提交修改事务时获取锁需要额外的步骤，锁作为一种确保一致性的机制，其开销是相当大的，并且在多个事务对图中的同一个元素同时试图进行修改时，可能会导致死锁。因此，只在在一致性比写入延迟更重要且冲突事务的数量很小的情况下，才应该使用锁。

在其它情况下，允许冲突事务继续运行，在读操作时解决不一致问题可能会更好。这是常用于大规模数据系统，且发生冲突的实际可能性很小时的最有效的方式。因此，写事务不会产生额外的开销，并且所有(尽管不太可能)发生的冲突都在读操作时进行探测并解决，并在随后进行清理。

#### 29.1.1.1. 分叉边
由于边在底层存储后端中是作为单独的记录而被存储的，同时对同一条边进行修改会导致冲突。使用 `ConsistncyModifier.FORK` 配置可以边标签，作为锁的替代。下面示例新创建了一个名为 `related` 的边标签，并且定义其一致性为 FORK：
```java
mgmt = graph.openManagement()
related = mgmt.makeEdgeLabel('related').make()
mgmt.setConsistency(related, ConsistencyModifier.FORK)
mgmt.commit()
```
在修改一个标签配置为 FORK 的边时，该边会被删除，被修改的边将会作为一条新边而被添加。因此，如果两个并发事务对同一条边进行修改， 则提交中会存在两份修改边的拷贝，如果需要，可在遍历查询期间解决(拷贝重复)。

> **注意**
> 边的分叉只使用与 MULTI 边。具有多重约束的边标签不能使用此策略，因为在边标签定义时构建了约束，此约束要求显式锁或使用底层存储后端的冲突解决机制。

#### 29.1.1.2. 多重属性
同时对顶点上的单值属性进行更改可能会引起冲突。与边相似，对于在修改时使用基数 LIST 和 FORK 定义的特定属性键，可以在顶点上允许任意数量的属性。因此，作为冲突的替代，会读取多个属性。由于 JanusGraph 允许属性的属性，诸如 `author` 这样的出处信息可以添加到属性中以便于在读操作的时候进行解析。

关于学习如何定义多重属性，请参见[多重属性](https://docs.janusgraph.org/latest/schema.html#property-cardinality)。

## 29.2. 数据不一致性
### 29.2.1. 暂时不一致性
在最终一致的存储后端上，写操作可能无法立刻对整个集群可见，这将导致图的暂时不一致性。就某种意义而言，这是最终一致性的固有属性：接受的更新必须传播到集群中的其它实例上，并且由于性能的因素，无法保证读操作的原子性。

从 JanusGraph 的角度来看，最终一致性可能会导致暂时的图的不一致性等由于事务的某些部分是可见的，而另一部分是不可见的而引起的不一致性。

**过期的索引条目**
索引条目可能指向不存在的顶点或边。同样，顶点或边缘可能出现在图中但尚未编入索引，因此被全局图形查询忽略。

**半边**
边只有一个方向被持久化或删除，这可能导致边缘没有被错误地被检索到。

> **注意**
> 为了避免图的暂时不一致性导致的写操作失败，推荐使用支持原子性批量写入的存储后端，并且保证允许原子性写操作启用。要使原子性写操作的优势派上用场，必须要让对单个事务进行修改的数量小于[第十三章，「配置参考」](https://docs.janusgraph.org/latest/config-ref.html)中记录的 `buffer-size` 配置选项。该缓冲区大小定义了 JanusGraph 支持对单个批处理保留的最大修改数量。如果一个事务有更多的修改，该持久化操作会被分为多个批处理操作分别持有，这对于批量加载非常有用但是会使写入操作失去原子性。

### 29.2.2. 幽灵顶点
最终一致的存储后端操作 JanusGraph 时可能会出现的永久性不一致，叫做 **幽灵顶点** 现象。如果顶点在被修改时同时被删除，则顶点可能会重新作为 **幽灵** 出现。

可以使用以下策略来缓解此问题：

**存在性检查**
在返回顶点之前，将事务配置为（双）检查顶点是否存在。更多相关信息请参见[10.8节「事务配置」](https://docs.janusgraph.org/latest/tx.html#tx-config)，并且注意这种方式可能会显着降低性能。请注意，这不能解决不一致问题，但会向用户隐藏其中一些。
**正则清理**
使用 [第35章 在 TinkerPop's Hadoop-Gremlin 下的 JanusGraph](https://docs.janusgraph.org/latest/hadoop-tp3.html) 运行常规批处理作业来修复图中的不一致性。这是唯一可以解决所有不一致问题并有效修复它们的策略。我们将在 Faunus 的未来版本中为此类修复提供越来越多的支持。
**软删除**
并非删除顶点，而是将其标记为已删除，将它们保留在图中以供将来分析，但将它们隐藏在面向用户的事务之外。
